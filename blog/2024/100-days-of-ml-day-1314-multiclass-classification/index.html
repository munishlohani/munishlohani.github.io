<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>A deep dive into multiclass classification using One-vs-Rest algorithm</p> <h3>Introduction</h3> <p>Previously, we worked on binary classification, using our MNIST dataset to distinguish 2 possible results: “5” or “not5”. Now, we will create a multiclass model to detect all ten digits.</p> <p>In simple words, Multiclass Classification involves more than 2 classes. A simple way to understand this process is by taking “number recognition” as an example where we classify input from 0–9.</p> <p>Some algorithms such as SGD classifiers, Random Forest Classifiers, and naïve Bayes are inherently designed to handle multiclass classification. On the other hand, algorithms like SVM or Logistic Regressions are strictly binary classifiers.</p> <p>Yet, we can use various techniques to perform a multiclass classification using multiple binary classifiers.</p> <h3>One-vs-Rest (OvR)</h3> <p>We create a separate binary classifier for each class in the One-vs-Rest strategy. This is like building “5” vs “not 5” classifiers for every digit. In this method, we run all classifiers on our instance and choose the class with the highest probability.</p> <h3>One-vs-One (OvO)</h3> <p>n the One-vs-One strategy, we train a binary classifier for every pair of digits, meaning for every N class, we have N×(N−1)/2N \times (N-1)/2N×(N−1)/2 classifiers. Then, based on the prediction count for each class, we see which class wins the most duels and declare it as our prediction. To understand better, let’s look at an example:</p> <p>Suppose we want to make a model to distinguish between red, blue, and green colors. For this, we create, (3 X 2)/2=3 classifiers:</p> <p>1. (red, blue)</p> <p>2. (red, green)</p> <p>3. (blue, green)</p> <p>Now, we take one color and then make predictions for each model. Suppose the first model predicts the color as ‘red’, the second one also predicts it as ‘red’, but the third model predicts it as ‘blue’. This gives red 2 points whereas blue 1 point. Based on this vote count, we expect the color to be red.</p> <h3>Training a Multiclass Classifier</h3> <pre>from sklearn.svm import SVC<br><br><br>svm_clf=SVC()<br>svm_clf.fit(X_train,y_train)<br><br></pre> <p>Firstly, let’s look at SVMs. Although SVMs do not natively handle multiclass classification, they can nonetheless be trained for this purpose. Sci-Kit learns itself to detect when to use the binary classification algorithm and when to use multiclass classification, automatically running OvR or OvO.</p> <p>Under the hood, Scikit-Learn uses the OvO algorithm for SVC as SVMs typically work better on this strategy due to its margin-based optimization.</p> <pre>svm_clf.predict(X_train[0].reshape(1,-1))<br><br><br># Output: array([5], dtype=uint8) </pre> <pre>scores=svm_clf.decision_function(X_train[0].reshape(1,-1))<br>scores<br><br># output: array([[ 1.72501977,  2.72809088,  7.2510018 ,  8.3076379 , -0.31087254,<br> #        9.3132482 ,  1.70975103,  2.76765202,  6.23049537,  4.84771048]])</pre> <p>The decision function gives scores for each class based on the 45 OvO model.</p> <p>However, we can also force Sci-Kit to learn to implement OvR or OvO algorithms.</p> <h4>One-vs-One</h4> <pre>from sklearn.multiclass import OneVsOneClassifier<br><br>ovo_cl=OneVsOneClassifier(SVC())<br><br>ovo_cl.fit(X_train,y_train)</pre> <pre>ovo_pred=ovo_cl.predict(X_train[0].reshape(1,-1))<br>ovo_scores=ovo_cl.decision_function(X_train[0].reshape(1,-1))<br>ovo_scores<br><br><br><br># Output: array([[ 2.72420789,  2.72909219,  7.25265966,  8.30764043, -0.31037527,<br>#         9.31302684,  0.70957317,  2.76678409,  6.22757724,  4.84005057]])</pre> <p>Here, the decision scores are the highest among the 45 models.</p> <h4>One-vs-Rest</h4> <pre>from sklearn.multiclass import OneVsRestClassifier<br><br><br>ovr_cl=OneVsRestClassifier(SVC())<br><br>ovr_cl.fit(X_train,y_train)</pre> <pre>ovr_cl.predict(X_train[0].reshape(1,-1))<br><br><br># output: array([5], dtype=uint8)</pre> <p>To get the exact number of estimators used to make a final prediction, we can use .estimators_ from sk-learn.</p> <pre>len(ovr_cl.estimators_)<br><br><br><br># Output: 10 (For OvR, there are as many models as there are classes. In our case, it's 10.)</pre> <p>By now, we have looked at an algorithm that does not natively handle multiclass classification. Now, let’s use an algorithm that can natively handle it. For now, let’s use SGDClassifier.</p> <pre>from sklearn.linear_model import SGDClassifier<br><br>sgd_clf=SGDClassifier()<br>sgd_clf.fit(X_train,y_train)</pre> <pre>sgd_clf.predict([X_train[0]])<br><br><br># Output: array([5], dtype=uint8)</pre> <pre>sgd_clf.decision_function([X_train[0]])<br><br><br># output: array([[-21552.37213583, -41286.82560334,  -8164.86249129,<br> #         1210.45049096, -25640.34563332,   2378.29018512,<br>  #      -19578.5361586 , -18033.75981984, -10719.81508551,<br>   #     -10666.77543211]]</pre> <p>The SGDClassifier looks much more convincing at predicting the numbers than SVC. However, there remains a doubt between 3 and 5.</p> <p>So, let’s evaluate our model.</p> <pre>from sklearn.model_selection import cross_val_score<br><br><br>cross_val_score(sgd_clf,X_train,y_train,cv=5,scoring="accuracy")<br><br><br># Output: array([0.89516667, 0.85358333, 0.86325   , 0.88225   , 0.88166667])</pre> <p>The accuracy is generally above 85%. To improve on this, we can scale the values. This can be done via StandardScaler</p> <pre>from sklearn.preprocessing import StandardScaler<br><br>scaler=StandardScaler()<br><br>X_train_scaled=scaler.fit_transform(X_train.astype(np.float64))<br>cross_val_score(sgd_clf,X_train_scaled,y_train,cv=5,scoring="accuracy")<br><br><br># Output: array([0.90266667, 0.8985    , 0.89975   , 0.89191667, 0.9045    ])</pre> <p>Now it looks much better!</p> <h3>Error Analysis</h3> <p>For now, let’s suppose we have found our best model and have successfully fine-tuned it. Now, let’s just look at ways to further enhance our model. One way of doing so is to analyze its errors.</p> <pre>from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix<br><br>y_train_pred=cross_val_predict(sgd_clf,X_train_scaled,y_train,cv=3)<br>cm=confusion_matrix(y_train,y_train_pred)<br><br>disp=ConfusionMatrixDisplay(confusion_matrix=cm)<br>disp.plot()</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/516/1*-RaC_TOz7V_CqltQ7ZD_0g.png"><figcaption>Confusion Matrix</figcaption></figure> <p>From our confusion matrix, we can infer that our model is reasonably accurate enough for most of our data. However, 5 remains quite green as compared to others. This can be due to less amount of data for “5” or due to difficulty in predicting it. To verify, we can compare error rates.</p> <pre>row_sums=np.sum(cm,axis=1)<br>err_conf_mx=cm/row_sums<br><br>np.fill_diagonal(err_conf_mx,0)<br>plt.matshow(err_conf_mx)<br>plt.show()</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/410/1*OxGARhWGk-QpMpptKVezDg.png"><figcaption>Error Rate</figcaption></figure> <p>From the figure, the column for “8” is quite bright as compared to others, meaning many images get misclassified as 8, mostly 3 and 5</p> <p>This can be due to various reasons: A common one being that the images are transformed.</p> <h3>Multilabel Classification</h3> <p>Sometimes, we may need to deal with data with multiple labels. A common example can be a photo classifier where we need to classify images based on the person present.</p> <p>While MNIST data doesn't come with multilabel, we can nonetheless modify it to accommodate different labels.</p> <pre>y_train_large=(y_train&gt;=5)<br>y_train_even=(y_train%2==0)<br><br>y_multilabel=np.c_[y_train_large,y_train_even]</pre> <p>This creates 2 labels for each digit: one to classify whether the digit is greater than 5 and the other to classify whether the digit is even.</p> <p>Now, let’s train it.</p> <pre>from sklearn.neighbors import KNeighborsClassifier<br><br>knn_clf=KNeighborsClassifier()<br>knn_clf.fit(X_train,y_multilabel)</pre> <pre>knn_clf.predict([X_train[0]])<br><br><br># Output: array([[ True, False]])</pre> <p>We know that our first digit is 5. Since it satisfies the condition, n≥5, the first label is true. For the second label, since (5%2 =/= 0) , it returns false</p> <p>Finally, let’s evaluate a model. To evaluate a model, we can use the same metrics as we did earlier. For multilabel, we will just be taking an average of the scores.</p> <pre>from sklearn.metrics import f1_score<br>f1_score(y_multilabel,y_train_knn,average="weighted")<br><br>#Output: 0.9812770550130211</pre> <h3>Reflection</h3> <p>With this chapter, I learned a lot about classification, its types as well as metrics to evaluate our model. The next blog will focus on questions/ projects related to classification.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=2c834b45a49c" width="1" height="1" alt=""></p> </body></html>
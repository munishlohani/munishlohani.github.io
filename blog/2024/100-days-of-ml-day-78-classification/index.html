<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>Exploring binary classification and some performance measures</p> <h3>Classification</h3> <p>Previously, while talking about supervised learning, I mentioned regression and classification as some of the most popular techniques. While my previous project (new one on the way!) focused on regression, this and a couple of blogs will solely focus on classification.</p> <h4>Introduction</h4> <p>Classification is a fundamental task in machine learning that involves predicting the category or class of our input based on its features. Simply put, it means giving labels to our input.</p> <h4>MNIST</h4> <p>As cited in the book, I will also be taking reference of the MNIST dataset. It is a set of 70,000 small images of handwritten digits. Each image is labelled with the digit it represents.</p> <pre>from sklearn.datasets import fetch_openml<br>import numpy as np<br><br>mnist=fetch_openml('mnist_784',version=1)</pre> <p>n the dataset, using mnist.keys(), we can access the dictionary keys from our set. Among these keys, DESCR contains a description of the dataset; data consists of an array with one row per instance and one column per feature; and target contains labels.</p> <p>To store it into X and y:</p> <pre>image=mnist.data.to_numpy()<br>X,y=image,mnist['target']</pre> <p>If we are to count total features and labels of the set, we can use NumPy's .shape attribute.</p> <pre>X.shape<br>y.shape<br><br># when executed seperately, output is:<br># (70000,784) for X and (70000,) for y</pre> <p>From this, we can infer that there are 70,000 data points and 784 features. Each feature is a representation of a pixel’s intensity. Since each image is 28x28 pixels, the total pixel count is 784.</p> <p>Now, let’s visualize some images:</p> <pre>plt.subplot(521)<br>plt.imshow(X[0].reshape(28,28),cmap=plt.cm.gray_r)<br>plt.subplot(522)<br>plt.imshow(X[1].reshape(28,28),cmap=plt.cm.gray_r)<br>plt.subplot(523)<br>plt.imshow(X[2].reshape(28,28),cmap=plt.cm.gray_r)<br>plt.subplot(524)<br>plt.imshow(X[3].reshape(28,28),cmap=plt.cm.gray_r)<br>plt.subplot(525)<br>plt.imshow(X[4].reshape(28,28),cmap=plt.cm.gray_r)<br>plt.subplot(526)<br>plt.imshow(X[5].reshape(28,28),cmap=plt.cm.gray_r)</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/384/1*5mhCUiIUXXNwTOMRIj5jUg.png"><figcaption>Output</figcaption></figure> <p>Now, let's look at y. Yes, it is a string. To convert it into an integer, we can use NumPy's .astype:</p> <pre>y=y.astype(np.uint8)</pre> <p>Finally, let’s split the data into a training set and a testing set. For now, we will separate 60,000 for training and the remaining 10,000 for testing.</p> <pre>X_train,X_test,y_train,y_test=X[:60000],X[60000:],y[:60000],y[60000:]</pre> <h4>Binary Classification</h4> <p>Binary classification involves two classes: either true or false. For now, let’s make a binary classifier that recognizes the number ‘5’.</p> <pre>y_train_5=(y_train==5)<br>y_test_5=(y_test==5)</pre> <p>Now, let’s pick a classifier to train it. For now, let’s use Stochastic Gradient Descent.</p> <pre>from sklearn.linear_model import SGDClassifier<br><br>sgd_clf=SGDClassifier(random_state=42)<br>sgd_clf.fit(X_train,y_train_5)</pre> <p>Let’s test it using the digit we used earlier</p> <pre>sgd_clf.predict(X_train[0].reshape(1,-1))<br><br>#Output: array([ True])</pre> <p>Finally, let’s evaluate our model.</p> <h4>Performance Measure</h4> <p>Evaluating a classification model is often trickier compared to regression ones. Hence, throughout this segment, we will look at different performance measures.</p> <p><strong>Using Cross-Validation for Accuracy</strong></p> <p>Before we run the code, let’s understand <strong>accuracy</strong>. Accuracy is a common performance metric for classification tasks when the dataset we are working on is balanced. It measures the proportion of correct predictions out of the total number of predictions made.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/496/1*QB6Xhu_CS8xoUVvQ6gSxFw.png"><figcaption>Accuracy</figcaption></figure> <pre>from sklearn.model_selection import cross_val_score<br><br><br>cross_val_score(sgd_clf,X_train,y_train_5,cv=5,scoring="accuracy")<br><br><br>#Output: array([0.95466667, 0.96975   , 0.9635    , 0.96533333, 0.94841667])</pre> <p>Although the scores are above 94%, they do not reflect true accuracy since 5s make up only 10% of the total data. To understand this better, let’s look at a model that returns “not 5” for every data point.</p> <pre>from sklearn.base import BaseEstimator<br><br>class Never5(BaseEstimator):<br>    def fit(self,X,y=None):<br>        return self<br>    def predict(self,X):<br>        return np.zeros((len(X),1),dtype=bool)</pre> <pre>never_5=Never5()<br>cross_val_score(never_5,X_train,y_train_5,cv=5,scoring="accuracy")<br><br>#Output: array([0.91266667, 0.90866667, 0.9095    , 0.90883333, 0.90858333])</pre> <p>Like earlier, the accuracy is quite high. Due to this reason, accuracy is generally not preferred for classification tasks where the data is skewed.</p> <p><strong>Confusion Matrix</strong></p> <p>The confusion matrix is another performance measure used in classification. It is a table that allows visualization of the algorithm’s performance.</p> <p><strong>Components of a Confusion Matrix</strong></p> <p>For binary classification, the confusion matrix summarizes 4 results in a 2x2 matrix.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/582/1*ed6_D322FMKQdhRVMFlAYw.png"><figcaption>Confusion Matrix</figcaption></figure> <p>Finally, let’s express this in code.</p> <pre>from sklearn.metrics import confusion_matrix<br>from sklearn.model_selection import cross_val_predict<br><br><br>y_train_pred=cross_val_predict(sgd_clf,X_train,y_train_5,cv=5)<br>confusion_matrix(y_train_5,y_train_pred)<br><br>#Output: array([[53115,  1464],<br>  #            [  916,  4505]], dtype=int64)</pre> <p>We can also represent this graphically.</p> <pre>from sklearn.metrics import ConfusionMatrixDisplay<br><br>_=ConfusionMatrixDisplay.from_predictions(y_train_5,y_train_pred)</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/551/1*Ro_QONheDeLxKEsRW2j00g.png"><figcaption>Confusion Matrix</figcaption></figure> <p>Each row of the confusion matrix contains the actual class while the columns consist of the predicted class. Here, the first row represents the actual not-5 (the false class): 53,115 of them were correctly classified as not-5 (true negative) whereas 1,464 were classified as 5 (false positive). Likewise, the second row contains the actual 5 class (the true class): 916 were classified as not-5 (false negative) whereas 4,505 were classified as 5 (true positive).</p> <h4>Reflection</h4> <p>The confusion matrix provides us with a lot of data that can be used for performance measures. However, sometimes, we may need a concise number. Thus, my next blog will primarily focus on such measures.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9aef15d9b95d" width="1" height="1" alt=""></p> </body></html>